<?php

declare(strict_types=1);

namespace Codewithkyrian\Tokenizers\Tests\Datasets\Models;

class LlamaDataset
{
    /**
     * Datasets for LLaMA-family tokenizers.
     *
     * @return array<string, array<string, array{text: string, tokens: string[], ids: int[], decoded: string}>>
     */
    public static function data(): array
    {
        return [
            'Xenova/llama3-tokenizer' => [
                'Simple' => [
                    'text' => TestStrings::SIMPLE,
                    'tokens' => ['How', 'Ä are', 'Ä you', 'Ä doing', '?'],
                    'ids' => [4438, 527, 499, 3815, 30],
                    'decoded' => 'How are you doing?',
                ],
                'Simple with punctuation' => [
                    'text' => TestStrings::SIMPLE_WITH_PUNCTUATION,
                    'tokens' => ['You', 'Ä should', "'ve", 'Ä done', 'Ä this'],
                    'ids' => [2675, 1288, 3077, 2884, 420],
                    'decoded' => "You should've done this",
                ],
                'Numbers' => [
                    'text' => TestStrings::NUMBERS,
                    'tokens' => ['012', '345', '678', '9', 'Ä ', '0', 'Ä ', '1', 'Ä ', '2', 'Ä ', '3', 'Ä ', '4', 'Ä ', '5', 'Ä ', '6', 'Ä ', '7', 'Ä ', '8', 'Ä ', '9', 'Ä ', '10', 'Ä ', '100', 'Ä ', '100', '0'],
                    'ids' => [11531, 12901, 17458, 24, 220, 15, 220, 16, 220, 17, 220, 18, 220, 19, 220, 20, 220, 21, 220, 22, 220, 23, 220, 24, 220, 605, 220, 1041, 220, 1041, 15],
                    'decoded' => '0123456789 0 1 2 3 4 5 6 7 8 9 10 100 1000',
                ],
                'Text with numbers' => [
                    'text' => TestStrings::TEXT_WITH_NUMBERS,
                    'tokens' => ['The', 'Ä company', 'Ä was', 'Ä founded', 'Ä in', 'Ä ', '201', '6', '.'],
                    'ids' => [791, 2883, 574, 18538, 304, 220, 679, 21, 13],
                    'decoded' => 'The company was founded in 2016.',
                ],
                'Punctuation' => [
                    'text' => TestStrings::PUNCTUATION,
                    'tokens' => ['A', 'ÄŠ', "'ll", 'Ä !!', 'to', "?'", 'd', "''", 'd', 'Ä of', ',', 'Ä can', "'t", '.'],
                    'ids' => [32, 198, 3358, 11261, 998, 20837, 67, 4708, 67, 315, 11, 649, 956, 13],
                    'decoded' => "A\n'll!!to?'d''d of, can't.",
                ],
                'Python code' => [
                    'text' => TestStrings::PYTHON_CODE,
                    'tokens' => ['def', 'Ä main', '():ÄŠ', 'Ä‰pass'],
                    'ids' => [755, 1925, 4019, 42531],
                    'decoded' => "def main():\n\tpass",
                ],
                'Javascript code' => [
                    'text' => TestStrings::JAVASCRIPT_CODE,
                    'tokens' => ['let', 'Ä a', 'Ä =', 'Ä obj', '.toString', '();ÄŠ', 'toString', '();'],
                    'ids' => [1169, 264, 284, 2909, 5180, 545, 6712, 2178],
                    'decoded' => "let a = obj.toString();\ntoString();",
                ],
                'Newlines' => [
                    'text' => TestStrings::LLAMA_NEWLINES,
                    'tokens' => ['ax', 'ÄŠ', '####ÄŠ', 'boo'],
                    'ids' => [710, 198, 71050, 34093],
                    'decoded' => "ax\n####\nboo",
                ],
                'Basic' => [
                    'text' => TestStrings::BASIC,
                    'tokens' => ['UN', 'want', 'ÃƒÂ©d', ',', 'running'],
                    'ids' => [1899, 53757, 15433, 11, 28272],
                    'decoded' => 'UNwantÃ©d,running',
                ],
                'Control tokens' => [
                    'text' => TestStrings::CONTROL_TOKENS,
                    'tokens' => ['1', 'Ä€', '2', 'Ã¯Â¿Â½', '3'],
                    'ids' => [16, 188, 17, 5809, 18],
                    'decoded' => "1\u{0000}2\u{fffd}3",
                ],
                'Hello world titlecase' => [
                    'text' => TestStrings::HELLO_WORLD_TITLECASE,
                    'tokens' => ['Hello', 'Ä World'],
                    'ids' => [9906, 4435],
                    'decoded' => 'Hello World',
                ],
                'Hello world lowercase' => [
                    'text' => TestStrings::HELLO_WORLD_LOWERCASE,
                    'tokens' => ['hello', 'Ä world'],
                    'ids' => [15339, 1917],
                    'decoded' => 'hello world',
                ],
                'Chinese only' => [
                    'text' => TestStrings::CHINESE_ONLY,
                    'tokens' => ['Ã§Ä¶ÅÃ¦Â´Â»', 'Ã§Ä¼Ä¦', 'Ã§Ä¾Å', 'Ã¨Â°', 'Ä½', 'Ã¦ÄºÂ¯'],
                    'ids' => [104654, 9554, 89151, 39013, 249, 21043],
                    'decoded' => 'ç”Ÿæ´»çš„çœŸè°›æ˜¯',
                ],
                'Leading space' => [
                    'text' => TestStrings::LEADING_SPACE,
                    'tokens' => ['Ä Ä ', 'Ä leading', 'Ä space'],
                    'ids' => [256, 6522, 3634],
                    'decoded' => '   leading space',
                ],
                'Trailing space' => [
                    'text' => TestStrings::TRAILING_SPACE,
                    'tokens' => ['tr', 'ailing', 'Ä space', 'Ä Ä Ä '],
                    'ids' => [376, 14612, 3634, 262],
                    'decoded' => 'trailing space   ',
                ],
                'Double space' => [
                    'text' => TestStrings::DOUBLE_SPACE,
                    'tokens' => ['Hi', 'Ä ', 'Ä Hello'],
                    'ids' => [13347, 220, 22691],
                    'decoded' => 'Hi  Hello',
                ],
                'Currency' => [
                    'text' => TestStrings::CURRENCY,
                    'tokens' => ['test', 'Ä $', '1', 'Ä R', '2', 'Ä #', '3', 'Ä Ã¢Ä¤Â¬', '4', 'Ä Ã‚Â£', '5', 'Ä Ã‚Â¥', '6', 'Ä Ã¢Ä¤', 'Â£', '7', 'Ä Ã¢Ä¤Â¹', '8', 'Ä Ã¢Ä¤', 'Â±', '9', 'Ä test'],
                    'ids' => [1985, 400, 16, 432, 17, 674, 18, 13281, 19, 7083, 20, 72588, 21, 113384, 96, 22, 90891, 23, 113384, 109, 24, 1296],
                    'decoded' => 'test $1 R2 #3 â‚¬4 Â£5 Â¥6 â‚£7 â‚¹8 â‚±9 test',
                ],
                'Currency with decimals' => [
                    'text' => TestStrings::CURRENCY_WITH_DECIMALS,
                    'tokens' => ['I', 'Ä bought', 'Ä an', 'Ä apple', 'Ä for', 'Ä $', '1', '.', '00', 'Ä at', 'Ä the', 'Ä store', '.'],
                    'ids' => [40, 11021, 459, 24149, 369, 400, 16, 13, 410, 520, 279, 3637, 13],
                    'decoded' => 'I bought an apple for $1.00 at the store.',
                ],
                'Ellipsis' => [
                    'text' => TestStrings::ELLIPSIS,
                    'tokens' => ['you', 'Ã¢Ä¢Â¦', 'Ä Ä '],
                    'ids' => [9514, 1981, 256],
                    'decoded' => 'youâ€¦  ',
                ],
                'Text with escape characters' => [
                    'text' => TestStrings::TEXT_WITH_ESCAPE_CHARACTERS,
                    'tokens' => ['you', 'Ã¢Ä¢Â¦', 'Ã‚Å‚Ã‚Å‚'],
                    'ids' => [9514, 1981, 9421],
                    'decoded' => "youâ€¦\u{00a0}\u{00a0}",
                ],
                'Text with escape characters 2' => [
                    'text' => TestStrings::TEXT_WITH_ESCAPE_CHARACTERS_2,
                    'tokens' => ['you', 'Ã¢Ä¢Â¦', 'Ã‚Å‚', 'Ã‚Å‚', 'you', 'Ã¢Ä¢Â¦', 'Ã‚Å‚Ã‚Å‚'],
                    'ids' => [9514, 1981, 4194, 4194, 9514, 1981, 9421],
                    'decoded' => "youâ€¦\u{00a0}\u{00a0}youâ€¦\u{00a0}\u{00a0}",
                ],
                'Tilde normalization' => [
                    'text' => TestStrings::TILDE_NORMALIZATION,
                    'tokens' => ['we', 'ird', 'Ä Ã¯Â½Å€', 'Ä edge', 'Ä Ã¯Â½Å€', 'Ä case'],
                    'ids' => [906, 2668, 111942, 6964, 111942, 1162],
                    'decoded' => 'weird ï½ž edge ï½ž case',
                ],
                'Spiece underscore' => [
                    'text' => TestStrings::SPIECE_UNDERSCORE,
                    'tokens' => ['Ã¢Ä¸', 'Ä£', 'This', 'Ä Ã¢Ä¸', 'Ä£', 'is', 'Ä Ã¢Ä¸', 'Ä£', 'a', 'Ä Ã¢Ä¸', 'Ä£', 'test', 'Ä Ã¢Ä¸', 'Ä£', '.'],
                    'ids' => [10634, 223, 2028, 14860, 223, 285, 14860, 223, 64, 14860, 223, 1985, 14860, 223, 13],
                    'decoded' => 'â–This â–is â–a â–test â–.',
                ],
                'Popular emojis' => [
                    'text' => TestStrings::POPULAR_EMOJIS,
                    'tokens' => ['Ã°ÅÄº', 'Ä¤', 'Ä Ã°ÅÄ³', 'Ä¯', 'Ä Ã°Å', 'Â¤', 'Â£', 'Ä Ã°ÅÄº', 'Ä¯', 'Ä Ã°ÅÄº', 'Åƒ', 'Ä Ã°Å', 'Ä°', 'Ä«', 'Ä Ã°Å', 'Ä»', 'Ä±', 'Ä Ã°ÅÄº', 'Ä¬', 'Ä Ã°ÅÄ¶', 'Â¥', 'Ä Ã°ÅÄº', 'Ä£', 'Ä Ã°ÅÄº', 'Ä§', 'Ä Ã°Å', 'Â¤', 'Ä¹', 'Ä Ã°ÅÄº', 'Ä¨', 'Ä Ã°ÅÄ³', 'Ä±', 'Ä Ã¢Ä¿Â¤', 'Ã¯Â¸Ä±', 'Ä Ã°ÅÄ´', 'Ä¾', 'Ä Ã°ÅÄ´', 'Ä¼', 'Ä Ã°ÅÄ´', 'Ä¹', 'Ä Ã°ÅÄ´', 'Ä»', 'Ä Ã°Å', 'Ä¸', 'Â¤', 'Ä Ã°ÅÄº', 'Ä°', 'Ä Ã°ÅÄ³', 'Ä®', 'Ä Ã°Å', 'Â¥', 'Â³', 'Ä Ã°ÅÄ´', 'Âª', 'Ä Ã¢Ä¾', 'Â¨', 'Ä Ã°ÅÄ³', 'Ä«', 'Ä Ã°ÅÄ³', 'Ä¢', 'Ä Ã°ÅÄ´', 'Â¯', 'Ä Ã°Å', 'Ä°', 'Äª', 'Ä Ã°Å', 'Ä»', 'Äª', 'Ä Ã°Å', 'Ä»', 'Ä®', 'Ä Ã°ÅÄ´', 'Ä¢', 'Ä Ã°ÅÄ³', 'Ä©', 'Ä Ã°ÅÄ³', 'Ä­', 'Ä Ã¢Ä¾', 'Ä§', 'Ä Ã°Å', 'Ä°', 'Ä£', 'Ä Ã°Å', 'Ä®', 'Å€', 'Ä Ã°Å', 'Ä®', 'Â¸', 'Ä Ã°ÅÄ´', 'Â°'],
                    'ids' => [76460, 224, 62904, 235, 11410, 97, 96, 27623, 235, 27623, 255, 11410, 236, 231, 11410, 247, 237, 27623, 232, 96169, 98, 27623, 223, 27623, 227, 11410, 97, 245, 27623, 228, 62904, 237, 71570, 31643, 64139, 250, 64139, 248, 64139, 245, 64139, 247, 11410, 244, 97, 27623, 236, 62904, 234, 11410, 98, 111, 64139, 103, 26602, 101, 62904, 231, 62904, 222, 64139, 107, 11410, 236, 230, 11410, 247, 230, 11410, 247, 234, 64139, 222, 62904, 229, 62904, 233, 26602, 227, 11410, 236, 223, 11410, 234, 252, 11410, 234, 116, 64139, 108],
                    'decoded' => 'ðŸ˜‚ ðŸ‘ ðŸ¤£ ðŸ˜ ðŸ˜­ ðŸŽ‰ ðŸ™ ðŸ˜Š ðŸ”¥ ðŸ˜ ðŸ˜… ðŸ¤— ðŸ˜† ðŸ‘ â¤ï¸ ðŸ’œ ðŸ’š ðŸ’— ðŸ’™ ðŸ–¤ ðŸ˜Ž ðŸ‘Œ ðŸ¥³ ðŸ’ª âœ¨ ðŸ‘‰ ðŸ‘€ ðŸ’¯ ðŸŽˆ ðŸ™ˆ ðŸ™Œ ðŸ’€ ðŸ‘‡ ðŸ‘‹ âœ… ðŸŽ ðŸŒž ðŸŒ¸ ðŸ’°',
                ],
                'Multibyte emojis' => [
                    'text' => TestStrings::MULTIBYTE_EMOJIS,
                    'tokens' => ['Ã¢Ä¾', 'Â¨', 'Ä Ã°Å', 'Â¤', 'Ä¹', 'Ä Ã°ÅÄ³', 'Ä£', 'Ã¯Â¸Ä±', 'Ä Ã°ÅÄ³', 'Â±', 'Ã°Å', 'Ä±', 'Â»', 'Ä Ã°Å', 'Ä·', 'Âµ', 'Ã¢Ä¢Ä¯', 'Ã¢Ä»', 'Ä¤', 'Ã¯Â¸Ä±', 'Ä Ã°Å', 'Â§', 'Ä»', 'Ã°Å', 'Ä±', 'Â»', 'Ã¢Ä¢Ä¯', 'Ã¢Ä»', 'Ä¤', 'Ä Ã°ÅÄ³', 'Â¨', 'Ã°Å', 'Ä±', 'Â»', 'Ã¢Ä¢Ä¯', 'Ã°Å', 'Ä®', 'Â¾', 'Ä Ã°Å', 'Â§', 'Ä³', 'Ã¢Ä¢Ä¯', 'Ã°Å', 'Â¤', 'Ä¿', 'Ã¢Ä¢Ä¯', 'Ã°Å', 'Â§', 'Ä³', 'Ä Ã°ÅÄ³', 'Â©', 'Ã¢Ä¢Ä¯', 'Ã¢Ä¿Â¤', 'Ã¢Ä¢Ä¯', 'Ã°ÅÄ´', 'Ä­', 'Ã¢Ä¢Ä¯', 'Ã°Å', 'Ä³', 'Â¨', 'Ä Ã°ÅÄ³', 'Â©', 'Ã¢Ä¢Ä¯', 'Ã°Å', 'Ä³', 'Â©', 'Ã¢Ä¢Ä¯', 'Ã°Å', 'Ä³', 'Â§', 'Ã¢Ä¢Ä¯', 'Ã°Å', 'Ä³', 'Â¦', 'Ä Ã°Å', 'Â§', 'Ä³', 'Ã°Å', 'Ä±', 'Â»', 'Ã¢Ä¢Ä¯', 'Ã°Å', 'Â¤', 'Ä¿', 'Ã¢Ä¢Ä¯', 'Ã°Å', 'Â§', 'Ä³', 'Ã°Å', 'Ä±', 'Â»', 'Ä Ã°Å', 'Ä±', 'Â´', 'Ã³', 'Å‚Ä£', 'Â§', 'Ã³', 'Å‚Ä£', 'Â¢', 'Ã³', 'Å‚Ä£', 'Â¥', 'Ã³', 'Å‚Ä£', 'Â®', 'Ã³', 'Å‚Ä£', 'Â§', 'Ã³', 'Å‚Ä£', 'Â¿', 'Ä Ã°ÅÄ³', 'Â¨', 'Ã°Å', 'Ä±', 'Â»', 'Ã¢Ä¢Ä¯', 'Ã¢Ä¿Â¤', 'Ã¯Â¸Ä±', 'Ã¢Ä¢Ä¯', 'Ã°ÅÄ´', 'Ä­', 'Ã¢Ä¢Ä¯', 'Ã°Å', 'Ä³', 'Â¨', 'Ã°Å', 'Ä±', 'Â¼'],
                    'ids' => [38798, 101, 11410, 97, 245, 62904, 223, 31643, 62904, 109, 9468, 237, 119, 11410, 243, 113, 102470, 17245, 224, 31643, 11410, 100, 247, 9468, 237, 119, 102470, 17245, 224, 62904, 101, 9468, 237, 119, 102470, 9468, 234, 122, 11410, 100, 239, 102470, 9468, 97, 251, 102470, 9468, 100, 239, 62904, 102, 102470, 121643, 102470, 93273, 233, 102470, 9468, 239, 101, 62904, 102, 102470, 9468, 239, 102, 102470, 9468, 239, 100, 102470, 9468, 239, 99, 11410, 100, 239, 9468, 237, 119, 102470, 9468, 97, 251, 102470, 9468, 100, 239, 9468, 237, 119, 11410, 237, 112, 175, 16050, 100, 175, 16050, 95, 175, 16050, 98, 175, 16050, 106, 175, 16050, 100, 175, 16050, 123, 62904, 101, 9468, 237, 119, 102470, 121643, 31643, 102470, 93273, 233, 102470, 9468, 239, 101, 9468, 237, 120],
                    'decoded' => 'âœ¨ ðŸ¤— ðŸ‘ï¸ ðŸ‘±ðŸ» ðŸ•µâ€â™‚ï¸ ðŸ§™ðŸ»â€â™‚ ðŸ‘¨ðŸ»â€ðŸŒ¾ ðŸ§‘â€ðŸ¤â€ðŸ§‘ ðŸ‘©â€â¤â€ðŸ’‹â€ðŸ‘¨ ðŸ‘©â€ðŸ‘©â€ðŸ‘§â€ðŸ‘¦ ðŸ§‘ðŸ»â€ðŸ¤â€ðŸ§‘ðŸ» ðŸ´ó §ó ¢ó ¥ó ®ó §ó ¿ ðŸ‘¨ðŸ»â€â¤ï¸â€ðŸ’‹â€ðŸ‘¨ðŸ¼',
                ],
                'BPE scores priority 1' => [
                    'text' => TestStrings::LLAMA_BPE_SCORES_PRIORITY_1,
                    'tokens' => ['grab', 'bed'],
                    'ids' => [59312, 2788],
                    'decoded' => 'grabbed',
                ],
                'BPE scores priority 2' => [
                    'text' => TestStrings::LLAMA_BPE_SCORES_PRIORITY_2,
                    'tokens' => ['Ä grabbed'],
                    'ids' => [30418],
                    'decoded' => ' grabbed',
                ],
                'BPE scores priority 3' => [
                    'text' => TestStrings::LLAMA_BPE_SCORES_PRIORITY_3,
                    'tokens' => ['Ä Ä Ä Ä Ä Ä Ä Ä Ä Ä ', 'Ä grabbed'],
                    'ids' => [1881, 30418],
                    'decoded' => '           grabbed',
                ],
                'Newline' => [
                    'text' => TestStrings::LLAMA_NEWLINE,
                    'tokens' => ['ÄŠ'],
                    'ids' => [198],
                    'decoded' => "\n",
                ],
                'Newline with leading space' => [
                    'text' => TestStrings::LLAMA_NEWLINE_WITH_LEADING_SPACE,
                    'tokens' => ['Ä ÄŠ'],
                    'ids' => [720],
                    'decoded' => " \n",
                ],
                'Tabs' => [
                    'text' => TestStrings::LLAMA_TABS,
                    'tokens' => ['Ä‰t', 'abs', 'Ä‰Ä‰Ä‰', 'Ä‰out', 'Ä here'],
                    'ids' => [3324, 3518, 573, 14294, 1618],
                    'decoded' => "\ttabs\t\t\t\tout here",
                ],
                'Newline and tab' => [
                    'text' => TestStrings::LLAMA_NEWLINE_AND_TAB,
                    'tokens' => ['ÄŠÄ‰ÄŠ'],
                    'ids' => [18108],
                    'decoded' => "\n\t\n",
                ],
                'Chinese letter' => [
                    'text' => TestStrings::LLAMA_CHINESE_LETTER,
                    'tokens' => ['Ã©Ä·Ä©'],
                    'ids' => [104643],
                    'decoded' => 'é•‡',
                ],
                'Emojis 1' => [
                    'text' => TestStrings::LLAMA_EMOJIS_1,
                    'tokens' => ['Ã°Å', 'Â¦', 'Ä»'],
                    'ids' => [9468, 99, 247],
                    'decoded' => 'ðŸ¦™',
                ],
                'Emojis 2' => [
                    'text' => TestStrings::LLAMA_EMOJIS_2,
                    'tokens' => ['Ã°Å', 'Â¦', 'Ä»', 'Ãª', 'Ä»', 'Ä¬'],
                    'ids' => [9468, 99, 247, 166, 247, 232],
                    'decoded' => 'ðŸ¦™ê™Š',
                ],
                'Emojis 3' => [
                    'text' => TestStrings::LLAMA_EMOJIS_3,
                    'tokens' => ['Ãª', 'Ä»', 'Ä¬', 'Ã°Å', 'Â¦', 'Ä»'],
                    'ids' => [166, 247, 232, 9468, 99, 247],
                    'decoded' => 'ê™ŠðŸ¦™',
                ],
                'Paragraph' => [
                    'text' => TestStrings::LLAMA_PARAGRAPH,
                    'tokens' => ['The', 'Ä llama', 'Ä (/', 'Ã‹', 'Äª', 'l', 'Ã‰', 'Ä³', 'Ã‹', 'Ä²', 'm', 'Ã‰Ä»', '/', ';', 'Ä Ã°Å', 'Â¦', 'Ä»', 'Spanish', 'Ä pronunciation', ':', 'Ä [', 'Ã‹', 'Äª', 'ÃŠ', 'Ä°', 'ama', '])', 'Ä (', 'L', 'ama', 'Ä gl', 'ama', ')', 'Ä is', 'Ä a', 'Ä domestic', 'ated', 'Ä South', 'Ä American', 'Ä camel', 'id', ',', 'Ä widely', 'Ä used', 'Ä as', 'Ä a', 'Ä meat', 'Ä and', 'Ä pack', 'Ä animal', 'Ä by', 'Ä And', 'ean', 'Ä cultures', 'Ä since', 'Ä the', 'Ä Pre', '-C', 'olum', 'bian', 'Ä era', '.', 'Ä L', 'lam', 'as', 'Ä are', 'Ä social', 'Ä animals', 'Ä and', 'Ä live', 'Ä with', 'Ä others', 'Ä as', 'Ä a', 'Ä herd', '.', 'Ä Their', 'Ä wool', 'Ä is', 'Ä soft', 'Ä and', 'Ä contains', 'Ä only', 'Ä a', 'Ä small', 'Ä amount', 'Ä of', 'Ä lan', 'olin', '.[', '2', ']', 'Ä L', 'lam', 'as', 'Ä can', 'Ä learn', 'Ä simple', 'Ä tasks', 'Ä after', 'Ä a', 'Ä few', 'Ä repetitions', '.', 'Ä When', 'Ä using', 'Ä a', 'Ä pack', ',', 'Ä they', 'Ä can', 'Ä carry', 'Ä about', 'Ä ', '25', 'Ä to', 'Ä ', '30', '%', 'Ä of', 'Ä their', 'Ä body', 'Ä weight', 'Ä for', 'Ä ', '8', 'Ä to', 'Ä ', '13', 'Ä km', 'Ä (', '5', 'Ã¢Ä¢Äµ', '8', 'Ä miles', ').[', '3', ']', 'Ä The', 'Ä name', 'Ä llama', 'Ä (', 'in', 'Ä the', 'Ä past', 'Ä also', 'Ä spelled', 'Ä "', 'lama', '"', 'Ä or', 'Ä "', 'gl', 'ama', '")', 'Ä was', 'Ä adopted', 'Ä by', 'Ä European', 'Ä settlers', 'Ä from', 'Ä native', 'Ä Per', 'uv', 'ians', '.[', '4', ']', 'Ä The', 'Ä ancestors', 'Ä of', 'Ä ll', 'amas', 'Ä are', 'Ä thought', 'Ä to', 'Ä have', 'Ä originated', 'Ä from', 'Ä the', 'Ä Great', 'Ä Plains', 'Ä of', 'Ä North', 'Ä America', 'Ä about', 'Ä ', '40', 'Ä million', 'Ä years', 'Ä ago', ',', 'Ä and', 'Ä subsequently', 'Ä migrated', 'Ä to', 'Ä South', 'Ä America', 'Ä about', 'Ä three', 'Ä million', 'Ä years', 'Ä ago', 'Ä during', 'Ä the', 'Ä Great', 'Ä American', 'Ä Inter', 'change', '.', 'Ä By', 'Ä the', 'Ä end', 'Ä of', 'Ä the', 'Ä last', 'Ä ice', 'Ä age', 'Ä (', '10', ',', '000', 'Ã¢Ä¢Äµ', '12', ',', '000', 'Ä years', 'Ä ago', '),', 'Ä camel', 'ids', 'Ä were', 'Ä extinct', 'Ä in', 'Ä North', 'Ä America', '.[', '3', ']', 'Ä As', 'Ä of', 'Ä ', '200', '7', ',', 'Ä there', 'Ä were', 'Ä over', 'Ä seven', 'Ä million', 'Ä ll', 'amas', 'Ä and', 'Ä al', 'pac', 'as', 'Ä in', 'Ä South', 'Ä America', 'Ä and', 'Ä over', 'Ä ', '158', ',', '000', 'Ä ll', 'amas', 'Ä and', 'Ä ', '100', ',', '000', 'Ãª', 'Ä»', 'Ä¬', 'Ã°Å', 'Â¦', 'Ä»', 'Ä al', 'pac', 'as', ',', 'Ä descended', 'Ä from', 'Ä progen', 'itors', 'Ä imported', 'Ä late', 'Ä in', 'Ä the', 'Ä ', '20', 'th', 'Ä century', ',', 'Ä in', 'Ä the', 'Ä United', 'Ä States', 'Ä and', 'Ä Canada', '.[', '5', ']', 'Ä In', 'Ä A', 'ym', 'ara', 'Ä mythology', ',', 'Ä ll', 'amas', 'Ä are', 'Ä important', 'Ä beings', '.', 'Ä The', 'Ä Heavenly', 'Ä L', 'lama', 'Ä is', 'Ä said', 'Ä to', 'Ä drink', 'Ä water', 'Ä from', 'Ä the', 'Ä ocean', 'Ä and', 'Ä ur', 'in', 'ates', 'Ä as', 'Ä it', 'Ä rains', '.[', '6', ']', 'Ä According', 'Ä to', 'Ä A', 'ym', 'ara', 'Ä es', 'chat', 'ology', ',', 'Ä ll', 'amas', 'Ä will', 'Ä return', 'Ä to', 'Ä the', 'Ä water', 'Ä springs', 'Ä and', 'Ä l', 'ago', 'ons', 'Ä where', 'Ä they', 'Ä come', 'Ä from', 'Ä at', 'Ä the', 'Ä end', 'Ä of', 'Ä time', '.[', '6', ']'],
                    'ids' => [791, 94776, 47325, 135, 230, 75, 133, 239, 135, 238, 76, 99638, 14, 26, 11410, 99, 247, 62897, 71722, 25, 510, 135, 230, 134, 236, 3105, 2526, 320, 43, 3105, 2840, 3105, 8, 374, 264, 13018, 660, 4987, 3778, 50252, 307, 11, 13882, 1511, 439, 264, 13339, 323, 3854, 10065, 555, 1628, 5420, 27833, 2533, 279, 5075, 7813, 1152, 13464, 11639, 13, 445, 24705, 300, 527, 3674, 10099, 323, 3974, 449, 3885, 439, 264, 59213, 13, 11205, 39640, 374, 8579, 323, 5727, 1193, 264, 2678, 3392, 315, 31791, 37737, 8032, 17, 60, 445, 24705, 300, 649, 4048, 4382, 9256, 1306, 264, 2478, 86066, 13, 3277, 1701, 264, 3854, 11, 814, 649, 6920, 922, 220, 914, 311, 220, 966, 4, 315, 872, 2547, 4785, 369, 220, 23, 311, 220, 1032, 13437, 320, 20, 4235, 23, 8931, 94638, 18, 60, 578, 836, 94776, 320, 258, 279, 3347, 1101, 68918, 330, 81101, 1, 477, 330, 6200, 3105, 909, 574, 18306, 555, 7665, 61107, 505, 10068, 3700, 12328, 5493, 8032, 19, 60, 578, 38618, 315, 9507, 29189, 527, 3463, 311, 617, 44853, 505, 279, 8681, 63911, 315, 4892, 5270, 922, 220, 1272, 3610, 1667, 4227, 11, 323, 28520, 73691, 311, 4987, 5270, 922, 2380, 3610, 1667, 4227, 2391, 279, 8681, 3778, 5783, 3455, 13, 3296, 279, 842, 315, 279, 1566, 10054, 4325, 320, 605, 11, 931, 4235, 717, 11, 931, 1667, 4227, 705, 50252, 3447, 1051, 69918, 304, 4892, 5270, 8032, 18, 60, 1666, 315, 220, 1049, 22, 11, 1070, 1051, 927, 8254, 3610, 9507, 29189, 323, 453, 46051, 300, 304, 4987, 5270, 323, 927, 220, 11286, 11, 931, 9507, 29189, 323, 220, 1041, 11, 931, 166, 247, 232, 9468, 99, 247, 453, 46051, 300, 11, 58842, 505, 84360, 12170, 25973, 3389, 304, 279, 220, 508, 339, 9478, 11, 304, 279, 3723, 4273, 323, 7008, 8032, 20, 60, 763, 362, 1631, 5169, 59492, 11, 9507, 29189, 527, 3062, 23837, 13, 578, 88150, 445, 81101, 374, 1071, 311, 7172, 3090, 505, 279, 18435, 323, 4433, 258, 988, 439, 433, 62555, 8032, 21, 60, 10771, 311, 362, 1631, 5169, 1560, 9884, 2508, 11, 9507, 29189, 690, 471, 311, 279, 3090, 42242, 323, 326, 6438, 2439, 1405, 814, 2586, 505, 520, 279, 842, 315, 892, 8032, 21, 60],
                    'decoded' => TestStrings::LLAMA_PARAGRAPH,
                ],
            ],
            'Xenova/deepseek-coder-1.3b-instruct' => [
                'Simple' => [
                    'text' => TestStrings::SIMPLE,
                    'tokens' => ['<ï½œbeginâ–ofâ–sentenceï½œ>', 'How', 'Ä are', 'Ä you', 'Ä doing', '?'],
                    'ids' => [32013, 2808, 417, 340, 3207, 30],
                    'decoded' => '<ï½œbeginâ–ofâ–sentenceï½œ>How are you doing?',
                ],
                'Simple with punctuation' => [
                    'text' => TestStrings::SIMPLE_WITH_PUNCTUATION,
                    'tokens' => ['<ï½œbeginâ–ofâ–sentenceï½œ>', 'You', 'Ä should', "'", 've', 'Ä done', 'Ä this'],
                    'ids' => [32013, 2042, 1020, 6, 312, 2359, 437],
                    'decoded' => "<ï½œbeginâ–ofâ–sentenceï½œ>You should've done this",
                ],
                'Numbers' => [
                    'text' => TestStrings::NUMBERS,
                    'tokens' => ['<ï½œbeginâ–ofâ–sentenceï½œ>', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'Ä ', '0', 'Ä ', '1', 'Ä ', '2', 'Ä ', '3', 'Ä ', '4', 'Ä ', '5', 'Ä ', '6', 'Ä ', '7', 'Ä ', '8', 'Ä ', '9', 'Ä ', '1', '0', 'Ä ', '1', '0', '0', 'Ä ', '1', '0', '0', '0'],
                    'ids' => [32013, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 207, 15, 207, 16, 207, 17, 207, 18, 207, 19, 207, 20, 207, 21, 207, 22, 207, 23, 207, 24, 207, 16, 15, 207, 16, 15, 15, 207, 16, 15, 15, 15],
                    'decoded' => '<ï½œbeginâ–ofâ–sentenceï½œ>0123456789 0 1 2 3 4 5 6 7 8 9 10 100 1000',
                ],
                'Text with numbers' => [
                    'text' => TestStrings::TEXT_WITH_NUMBERS,
                    'tokens' => ['<ï½œbeginâ–ofâ–sentenceï½œ>', 'The', 'Ä company', 'Ä was', 'Ä founded', 'Ä in', 'Ä ', '2', '0', '1', '6', '.'],
                    'ids' => [32013, 546, 2595, 438, 16316, 279, 207, 17, 15, 16, 21, 13],
                    'decoded' => '<ï½œbeginâ–ofâ–sentenceï½œ>The company was founded in 2016.',
                ],
                'Punctuation' => [
                    'text' => TestStrings::PUNCTUATION,
                    'tokens' => ['<ï½œbeginâ–ofâ–sentenceï½œ>', 'A', 'ÄŠ', "'", 'll', 'Ä !!', 'to', "?'", 'd', "''", 'd', 'Ä of', ',', 'Ä can', "'", 't', '.'],
                    'ids' => [32013, 32, 185, 6, 642, 24466, 577, 11665, 67, 4191, 67, 280, 11, 482, 6, 83, 13],
                    'decoded' => "<ï½œbeginâ–ofâ–sentenceï½œ>A\n'll !!to?'d''d of, can't.",
                ],
                'Python code' => [
                    'text' => TestStrings::PYTHON_CODE,
                    'tokens' => ['<ï½œbeginâ–ofâ–sentenceï½œ>', 'def', 'Ä main', '():', 'ÄŠ', 'Ä‰', 'pass'],
                    'ids' => [32013, 1551, 1959, 10942, 185, 184, 4805],
                    'decoded' => "<ï½œbeginâ–ofâ–sentenceï½œ>def main():\n\tpass",
                ],
                'Javascript code' => [
                    'text' => TestStrings::JAVASCRIPT_CODE,
                    'tokens' => ['<ï½œbeginâ–ofâ–sentenceï½œ>', 'let', 'Ä a', 'Ä =', 'Ä obj', '.', 'toString', '();', 'ÄŠ', 'toString', '();'],
                    'ids' => [32013, 1160, 245, 405, 6528, 13, 12617, 1293, 185, 12617, 1293],
                    'decoded' => "<ï½œbeginâ–ofâ–sentenceï½œ>let a = obj.toString();\ntoString();",
                ],
                'Newlines' => [
                    'text' => TestStrings::LLAMA_NEWLINES,
                    'tokens' => ['<ï½œbeginâ–ofâ–sentenceï½œ>', 'ax', 'ÄŠ', '####', 'ÄŠ', 'bo', 'o'],
                    'ids' => [32013, 1099, 185, 3576, 185, 952, 78],
                    'decoded' => "<ï½œbeginâ–ofâ–sentenceï½œ>ax\n####\nboo",
                ],
                'Basic' => [
                    'text' => TestStrings::BASIC,
                    'tokens' => ['<ï½œbeginâ–ofâ–sentenceï½œ>', 'UN', 'want', 'ÃƒÂ©d', ',', 'running'],
                    'ids' => [32013, 4348, 28626, 31898, 11, 22785],
                    'decoded' => '<ï½œbeginâ–ofâ–sentenceï½œ>UNwantÃ©d,running',
                ],
                'Control tokens' => [
                    'text' => TestStrings::CONTROL_TOKENS,
                    'tokens' => ['<ï½œbeginâ–ofâ–sentenceï½œ>', '1', 'Ä€', '2', 'Ã¯Â¿Â½', '3'],
                    'ids' => [32013, 16, 175, 17, 10006, 18],
                    'decoded' => "<ï½œbeginâ–ofâ–sentenceï½œ>1\u{0000}2\u{fffd}3",
                ],
                'Hello world titlecase' => [
                    'text' => TestStrings::HELLO_WORLD_TITLECASE,
                    'tokens' => ['<ï½œbeginâ–ofâ–sentenceï½œ>', 'Hello', 'Ä World'],
                    'ids' => [32013, 17535, 5414],
                    'decoded' => '<ï½œbeginâ–ofâ–sentenceï½œ>Hello World',
                ],
                'Hello world lowercase' => [
                    'text' => TestStrings::HELLO_WORLD_LOWERCASE,
                    'tokens' => ['<ï½œbeginâ–ofâ–sentenceï½œ>', 'hello', 'Ä world'],
                    'ids' => [32013, 31702, 1835],
                    'decoded' => '<ï½œbeginâ–ofâ–sentenceï½œ>hello world',
                ],
                'Chinese only' => [
                    'text' => TestStrings::CHINESE_ONLY,
                    'tokens' => ['<ï½œbeginâ–ofâ–sentenceï½œ>', 'Ã§Ä¶ÅÃ¦Â´Â»Ã§Ä¼Ä¦', 'Ã§Ä¾Å', 'Ã¨Â°', 'Ä½', 'Ã¦ÄºÂ¯'],
                    'ids' => [32013, 23393, 2651, 1534, 236, 502],
                    'decoded' => '<ï½œbeginâ–ofâ–sentenceï½œ>ç”Ÿæ´»çš„çœŸè°›æ˜¯',
                ],
                'Leading space' => [
                    'text' => TestStrings::LEADING_SPACE,
                    'tokens' => ['<ï½œbeginâ–ofâ–sentenceï½œ>', 'Ä Ä ', 'Ä leading', 'Ä space'],
                    'ids' => [32013, 243, 5877, 2507],
                    'decoded' => '<ï½œbeginâ–ofâ–sentenceï½œ>   leading space',
                ],
                'Trailing space' => [
                    'text' => TestStrings::TRAILING_SPACE,
                    'tokens' => ['<ï½œbeginâ–ofâ–sentenceï½œ>', 'tra', 'iling', 'Ä space', 'Ä Ä Ä '],
                    'ids' => [32013, 7246, 5964, 2507, 315],
                    'decoded' => '<ï½œbeginâ–ofâ–sentenceï½œ>trailing space   ',
                ],
                'Double space' => [
                    'text' => TestStrings::DOUBLE_SPACE,
                    'tokens' => ['<ï½œbeginâ–ofâ–sentenceï½œ>', 'Hi', 'Ä ', 'Ä H', 'ello'],
                    'ids' => [32013, 11041, 207, 414, 9489],
                    'decoded' => '<ï½œbeginâ–ofâ–sentenceï½œ>Hi  Hello',
                ],
                'Currency' => [
                    'text' => TestStrings::CURRENCY,
                    'tokens' => ['<ï½œbeginâ–ofâ–sentenceï½œ>', 'test', 'Ä $', '1', 'Ä R', '2', 'Ä #', '3', 'Ä ', 'Ã¢Ä¤Â¬', '4', 'Ä Ã‚Â£', '5', 'Ä Ã‚', 'Â¥', '6', 'Ä ', 'Ã¢Ä¤', 'Â£', '7', 'Ä ', 'Ã¢Ä¤', 'Â¹', '8', 'Ä ', 'Ã¢Ä¤', 'Â±', '9', 'Ä test'],
                    'ids' => [32013, 2806, 371, 16, 432, 17, 1494, 18, 207, 11010, 19, 8761, 20, 2688, 98, 21, 207, 7935, 96, 22, 207, 7935, 117, 23, 207, 7935, 109, 24, 1719],
                    'decoded' => '<ï½œbeginâ–ofâ–sentenceï½œ>test $1 R2 #3 â‚¬4 Â£5 Â¥6 â‚£7 â‚¹8 â‚±9 test',
                ],
                'Currency with decimals' => [
                    'text' => TestStrings::CURRENCY_WITH_DECIMALS,
                    'tokens' => ['<ï½œbeginâ–ofâ–sentenceï½œ>', 'I', 'Ä bought', 'Ä an', 'Ä apple', 'Ä for', 'Ä $', '1', '.', '0', '0', 'Ä at', 'Ä the', 'Ä store', '.'],
                    'ids' => [32013, 40, 8942, 274, 15902, 327, 371, 16, 13, 15, 15, 429, 254, 4730, 13],
                    'decoded' => '<ï½œbeginâ–ofâ–sentenceï½œ>I bought an apple for $1.00 at the store.',
                ],
                'Ellipsis' => [
                    'text' => TestStrings::ELLIPSIS,
                    'tokens' => ['<ï½œbeginâ–ofâ–sentenceï½œ>', 'you', 'Ã¢Ä¢Â¦', 'Ä Ä '],
                    'ids' => [32013, 4209, 2484, 243],
                    'decoded' => '<ï½œbeginâ–ofâ–sentenceï½œ>youâ€¦  ',
                ],
                'Text with escape characters' => [
                    'text' => TestStrings::TEXT_WITH_ESCAPE_CHARACTERS,
                    'tokens' => ['<ï½œbeginâ–ofâ–sentenceï½œ>', 'you', 'Ã¢Ä¢Â¦', 'Ã‚Å‚Ã‚Å‚'],
                    'ids' => [32013, 4209, 2484, 10447],
                    'decoded' => "<ï½œbeginâ–ofâ–sentenceï½œ>youâ€¦\u{00a0}\u{00a0}",
                ],
                'Text with escape characters 2' => [
                    'text' => TestStrings::TEXT_WITH_ESCAPE_CHARACTERS_2,
                    'tokens' => ['<ï½œbeginâ–ofâ–sentenceï½œ>', 'you', 'Ã¢Ä¢Â¦', 'Ã‚Å‚', 'Ã‚Å‚', 'you', 'Ã¢Ä¢Â¦', 'Ã‚Å‚Ã‚Å‚'],
                    'ids' => [32013, 4209, 2484, 1200, 1200, 4209, 2484, 10447],
                    'decoded' => "<ï½œbeginâ–ofâ–sentenceï½œ>youâ€¦\u{00a0}\u{00a0}youâ€¦\u{00a0}\u{00a0}",
                ],
                'Tilde normalization' => [
                    'text' => TestStrings::TILDE_NORMALIZATION,
                    'tokens' => ['<ï½œbeginâ–ofâ–sentenceï½œ>', 'we', 'ird', 'Ä ', 'Ã¯', 'Â½', 'Å€', 'Ä edge', 'Ä ', 'Ã¯', 'Â½', 'Å€', 'Ä case'],
                    'ids' => [32013, 828, 2369, 207, 169, 121, 239, 5935, 207, 169, 121, 239, 1452],
                    'decoded' => '<ï½œbeginâ–ofâ–sentenceï½œ>weird ï½ž edge ï½ž case',
                ],
                'Popular emojis' => [
                    'text' => TestStrings::POPULAR_EMOJIS,
                    'tokens' => ['<ï½œbeginâ–ofâ–sentenceï½œ>', 'Ã°Å', 'Äº', 'Ä¤', 'Ä Ã°Å', 'Ä³', 'Ä¯', 'Ä Ã°Å', 'Â¤', 'Â£', 'Ä Ã°Å', 'Äº', 'Ä¯', 'Ä Ã°Å', 'Äº', 'Åƒ', 'Ä Ã°Å', 'Ä°', 'Ä«', 'Ä Ã°ÅÄ»', 'Ä±', 'Ä Ã°Å', 'Äº', 'Ä¬', 'Ä Ã°Å', 'Ä¶', 'Â¥', 'Ä Ã°Å', 'Äº', 'Ä£', 'Ä Ã°Å', 'Äº', 'Ä§', 'Ä Ã°Å', 'Â¤', 'Ä¹', 'Ä Ã°Å', 'Äº', 'Ä¨', 'Ä Ã°Å', 'Ä³', 'Ä±', 'Ä ', 'Ã¢', 'Ä¿', 'Â¤', 'Ã¯', 'Â¸', 'Ä±', 'Ä Ã°Å', 'Ä´', 'Ä¾', 'Ä Ã°Å', 'Ä´', 'Ä¼', 'Ä Ã°Å', 'Ä´', 'Ä¹', 'Ä Ã°Å', 'Ä´', 'Ä»', 'Ä Ã°Å', 'Ä¸', 'Â¤', 'Ä Ã°Å', 'Äº', 'Ä°', 'Ä Ã°Å', 'Ä³', 'Ä®', 'Ä Ã°Å', 'Â¥', 'Â³', 'Ä Ã°Å', 'Ä´', 'Âª', 'Ä ', 'Ã¢', 'Ä¾', 'Â¨', 'Ä Ã°Å', 'Ä³', 'Ä«', 'Ä Ã°Å', 'Ä³', 'Ä¢', 'Ä Ã°Å', 'Ä´', 'Â¯', 'Ä Ã°Å', 'Ä°', 'Äª', 'Ä Ã°ÅÄ»', 'Äª', 'Ä Ã°ÅÄ»', 'Ä®', 'Ä Ã°Å', 'Ä´', 'Ä¢', 'Ä Ã°Å', 'Ä³', 'Ä©', 'Ä Ã°Å', 'Ä³', 'Ä­', 'Ä ', 'Ã¢', 'Ä¾', 'Ä§', 'Ä Ã°Å', 'Ä°', 'Ä£', 'Ä Ã°Å', 'Ä®', 'Å€', 'Ä Ã°Å', 'Ä®', 'Â¸', 'Ä Ã°Å', 'Ä´', 'Â°'],
                    'ids' => [32013, 10047, 233, 211, 12394, 226, 222, 12394, 97, 96, 12394, 233, 222, 12394, 233, 242, 12394, 223, 218, 22709, 224, 12394, 233, 219, 12394, 229, 98, 12394, 233, 210, 12394, 233, 214, 12394, 97, 232, 12394, 233, 215, 12394, 226, 224, 207, 156, 238, 97, 169, 116, 224, 12394, 227, 237, 12394, 227, 235, 12394, 227, 232, 12394, 227, 234, 12394, 231, 97, 12394, 233, 223, 12394, 226, 221, 12394, 98, 111, 12394, 227, 103, 207, 156, 237, 101, 12394, 226, 218, 12394, 226, 209, 12394, 227, 107, 12394, 223, 217, 22709, 217, 22709, 221, 12394, 227, 209, 12394, 226, 216, 12394, 226, 220, 207, 156, 237, 214, 12394, 223, 210, 12394, 221, 239, 12394, 221, 116, 12394, 227, 108],
                    'decoded' => '<ï½œbeginâ–ofâ–sentenceï½œ>ðŸ˜‚ ðŸ‘ ðŸ¤£ ðŸ˜ ðŸ˜­ ðŸŽ‰ ðŸ™ ðŸ˜Š ðŸ”¥ ðŸ˜ ðŸ˜… ðŸ¤— ðŸ˜† ðŸ‘ â¤ï¸ ðŸ’œ ðŸ’š ðŸ’— ðŸ’™ ðŸ–¤ ðŸ˜Ž ðŸ‘Œ ðŸ¥³ ðŸ’ª âœ¨ ðŸ‘‰ ðŸ‘€ ðŸ’¯ ðŸŽˆ ðŸ™ˆ ðŸ™Œ ðŸ’€ ðŸ‘‡ ðŸ‘‹ âœ… ðŸŽ ðŸŒž ðŸŒ¸ ðŸ’°',
                ],
                'Multibyte emojis' => [
                    'text' => TestStrings::MULTIBYTE_EMOJIS,
                    'tokens' => ['<ï½œbeginâ–ofâ–sentenceï½œ>', 'Ã¢', 'Ä¾', 'Â¨', 'Ä Ã°Å', 'Â¤', 'Ä¹', 'Ä Ã°Å', 'Ä³', 'Ä£', 'Ã¯', 'Â¸', 'Ä±', 'Ä Ã°Å', 'Ä³', 'Â±', 'Ã°Å', 'Ä±', 'Â»', 'Ä Ã°Å', 'Ä·', 'Âµ', 'Ã¢Ä¢', 'Ä¯', 'Ã¢', 'Ä»', 'Ä¤', 'Ã¯', 'Â¸', 'Ä±', 'Ä Ã°Å', 'Â§', 'Ä»', 'Ã°Å', 'Ä±', 'Â»', 'Ã¢Ä¢', 'Ä¯', 'Ã¢', 'Ä»', 'Ä¤', 'Ä Ã°Å', 'Ä³', 'Â¨', 'Ã°Å', 'Ä±', 'Â»', 'Ã¢Ä¢', 'Ä¯', 'Ã°Å', 'Ä®', 'Â¾', 'Ä Ã°Å', 'Â§', 'Ä³', 'Ã¢Ä¢', 'Ä¯', 'Ã°Å', 'Â¤', 'Ä¿', 'Ã¢Ä¢', 'Ä¯', 'Ã°Å', 'Â§', 'Ä³', 'Ä Ã°Å', 'Ä³', 'Â©', 'Ã¢Ä¢', 'Ä¯', 'Ã¢', 'Ä¿', 'Â¤', 'Ã¢Ä¢', 'Ä¯', 'Ã°Å', 'Ä´', 'Ä­', 'Ã¢Ä¢', 'Ä¯', 'Ã°Å', 'Ä³', 'Â¨', 'Ä Ã°Å', 'Ä³', 'Â©', 'Ã¢Ä¢', 'Ä¯', 'Ã°Å', 'Ä³', 'Â©', 'Ã¢Ä¢', 'Ä¯', 'Ã°Å', 'Ä³', 'Â§', 'Ã¢Ä¢', 'Ä¯', 'Ã°Å', 'Ä³', 'Â¦', 'Ä Ã°Å', 'Â§', 'Ä³', 'Ã°Å', 'Ä±', 'Â»', 'Ã¢Ä¢', 'Ä¯', 'Ã°Å', 'Â¤', 'Ä¿', 'Ã¢Ä¢', 'Ä¯', 'Ã°Å', 'Â§', 'Ä³', 'Ã°Å', 'Ä±', 'Â»', 'Ä Ã°Å', 'Ä±', 'Â´', 'Ã³', 'Å‚', 'Ä£', 'Â§', 'Ã³', 'Å‚', 'Ä£', 'Â¢', 'Ã³', 'Å‚', 'Ä£', 'Â¥', 'Ã³', 'Å‚', 'Ä£', 'Â®', 'Ã³', 'Å‚', 'Ä£', 'Â§', 'Ã³', 'Å‚', 'Ä£', 'Â¿', 'Ä Ã°Å', 'Ä³', 'Â¨', 'Ã°Å', 'Ä±', 'Â»', 'Ã¢Ä¢', 'Ä¯', 'Ã¢', 'Ä¿', 'Â¤', 'Ã¯', 'Â¸', 'Ä±', 'Ã¢Ä¢', 'Ä¯', 'Ã°Å', 'Ä´', 'Ä­', 'Ã¢Ä¢', 'Ä¯', 'Ã°Å', 'Ä³', 'Â¨', 'Ã°Å', 'Ä±', 'Â¼'],
                    'ids' => [32013, 156, 237, 101, 12394, 97, 232, 12394, 226, 210, 169, 116, 224, 12394, 226, 109, 10047, 224, 119, 12394, 230, 113, 350, 222, 156, 234, 211, 169, 116, 224, 12394, 100, 234, 10047, 224, 119, 350, 222, 156, 234, 211, 12394, 226, 101, 10047, 224, 119, 350, 222, 10047, 221, 122, 12394, 100, 226, 350, 222, 10047, 97, 238, 350, 222, 10047, 100, 226, 12394, 226, 102, 350, 222, 156, 238, 97, 350, 222, 10047, 227, 220, 350, 222, 10047, 226, 101, 12394, 226, 102, 350, 222, 10047, 226, 102, 350, 222, 10047, 226, 100, 350, 222, 10047, 226, 99, 12394, 100, 226, 10047, 224, 119, 350, 222, 10047, 97, 238, 350, 222, 10047, 100, 226, 10047, 224, 119, 12394, 224, 112, 173, 241, 210, 100, 173, 241, 210, 95, 173, 241, 210, 98, 173, 241, 210, 106, 173, 241, 210, 100, 173, 241, 210, 123, 12394, 226, 101, 10047, 224, 119, 350, 222, 156, 238, 97, 169, 116, 224, 350, 222, 10047, 227, 220, 350, 222, 10047, 226, 101, 10047, 224, 120],
                    'decoded' => '<ï½œbeginâ–ofâ–sentenceï½œ>âœ¨ ðŸ¤— ðŸ‘ï¸ ðŸ‘±ðŸ» ðŸ•µâ€â™‚ï¸ ðŸ§™ðŸ»â€â™‚ ðŸ‘¨ðŸ»â€ðŸŒ¾ ðŸ§‘â€ðŸ¤â€ðŸ§‘ ðŸ‘©â€â¤â€ðŸ’‹â€ðŸ‘¨ ðŸ‘©â€ðŸ‘©â€ðŸ‘§â€ðŸ‘¦ ðŸ§‘ðŸ»â€ðŸ¤â€ðŸ§‘ðŸ» ðŸ´ó §ó ¢ó ¥ó ®ó §ó ¿ ðŸ‘¨ðŸ»â€â¤ï¸â€ðŸ’‹â€ðŸ‘¨ðŸ¼',
                ],
                'Spiece underscore' => [
                    'text' => TestStrings::SPIECE_UNDERSCORE,
                    'tokens' => ['<ï½œbeginâ–ofâ–sentenceï½œ>', 'Ã¢Ä¸', 'Ä£', 'This', 'Ä ', 'Ã¢Ä¸', 'Ä£', 'is', 'Ä ', 'Ã¢Ä¸', 'Ä£', 'a', 'Ä ', 'Ã¢Ä¸', 'Ä£', 'test', 'Ä ', 'Ã¢Ä¸', 'Ä£', '.'],
                    'ids' => [32013, 11028, 210, 1559, 207, 11028, 210, 262, 207, 11028, 210, 64, 207, 11028, 210, 2806, 207, 11028, 210, 13],
                    'decoded' => '<ï½œbeginâ–ofâ–sentenceï½œ>â–This â–is â–a â–test â–.',
                ],
                'BPE scores priority 1' => [
                    'text' => TestStrings::LLAMA_BPE_SCORES_PRIORITY_1,
                    'tokens' => ['<ï½œbeginâ–ofâ–sentenceï½œ>', 'gr', 'ab', 'bed'],
                    'ids' => [32013, 877, 356, 3861],
                    'decoded' => '<ï½œbeginâ–ofâ–sentenceï½œ>grabbed',
                ],
                'BPE scores priority 2' => [
                    'text' => TestStrings::LLAMA_BPE_SCORES_PRIORITY_2,
                    'tokens' => ['<ï½œbeginâ–ofâ–sentenceï½œ>', 'Ä grab', 'bed'],
                    'ids' => [32013, 14596, 3861],
                    'decoded' => '<ï½œbeginâ–ofâ–sentenceï½œ> grabbed',
                ],
                'BPE scores priority 3' => [
                    'text' => TestStrings::LLAMA_BPE_SCORES_PRIORITY_3,
                    'tokens' => ['<ï½œbeginâ–ofâ–sentenceï½œ>', 'Ä Ä Ä Ä Ä Ä Ä Ä Ä Ä ', 'Ä grab', 'bed'],
                    'ids' => [32013, 3137, 14596, 3861],
                    'decoded' => '<ï½œbeginâ–ofâ–sentenceï½œ>           grabbed',
                ],
                'Newline' => [
                    'text' => TestStrings::LLAMA_NEWLINE,
                    'tokens' => ['<ï½œbeginâ–ofâ–sentenceï½œ>', 'ÄŠ'],
                    'ids' => [32013, 185],
                    'decoded' => "<ï½œbeginâ–ofâ–sentenceï½œ>\n",
                ],
                'Newline with leading space' => [
                    'text' => TestStrings::LLAMA_NEWLINE_WITH_LEADING_SPACE,
                    'tokens' => ['<ï½œbeginâ–ofâ–sentenceï½œ>', 'Ä ', 'ÄŠ'],
                    'ids' => [32013, 207, 185],
                    'decoded' => "<ï½œbeginâ–ofâ–sentenceï½œ> \n",
                ],
                'Tabs' => [
                    'text' => TestStrings::LLAMA_TABS,
                    'tokens' => ['<ï½œbeginâ–ofâ–sentenceï½œ>', 'Ä‰', 'tabs', 'Ä‰Ä‰Ä‰', 'Ä‰', 'out', 'Ä here'],
                    'ids' => [32013, 184, 20611, 1749, 184, 406, 1283],
                    'decoded' => "<ï½œbeginâ–ofâ–sentenceï½œ>\ttabs\t\t\t\tout here",
                ],
                'Newline and tab' => [
                    'text' => TestStrings::LLAMA_NEWLINE_AND_TAB,
                    'tokens' => ['<ï½œbeginâ–ofâ–sentenceï½œ>', 'ÄŠ', 'Ä‰', 'ÄŠ'],
                    'ids' => [32013, 185, 184, 185],
                    'decoded' => "<ï½œbeginâ–ofâ–sentenceï½œ>\n\t\n",
                ],
                'Chinese letter' => [
                    'text' => TestStrings::LLAMA_CHINESE_LETTER,
                    'tokens' => ['<ï½œbeginâ–ofâ–sentenceï½œ>', 'Ã©Ä·Ä©'],
                    'ids' => [32013, 6759],
                    'decoded' => '<ï½œbeginâ–ofâ–sentenceï½œ>é•‡',
                ],
                'Emojis 1' => [
                    'text' => TestStrings::LLAMA_EMOJIS_1,
                    'tokens' => ['<ï½œbeginâ–ofâ–sentenceï½œ>', 'Ã°Å', 'Â¦', 'Ä»'],
                    'ids' => [32013, 10047, 99, 234],
                    'decoded' => '<ï½œbeginâ–ofâ–sentenceï½œ>ðŸ¦™',
                ],
                'Emojis 2' => [
                    'text' => TestStrings::LLAMA_EMOJIS_2,
                    'tokens' => ['<ï½œbeginâ–ofâ–sentenceï½œ>', 'Ã°Å', 'Â¦', 'Ä»', 'Ãª', 'Ä»', 'Ä¬'],
                    'ids' => [32013, 10047, 99, 234, 164, 234, 219],
                    'decoded' => '<ï½œbeginâ–ofâ–sentenceï½œ>ðŸ¦™ê™Š',
                ],
                'Emojis 3' => [
                    'text' => TestStrings::LLAMA_EMOJIS_3,
                    'tokens' => ['<ï½œbeginâ–ofâ–sentenceï½œ>', 'Ãª', 'Ä»', 'Ä¬', 'Ã°Å', 'Â¦', 'Ä»'],
                    'ids' => [32013, 164, 234, 219, 10047, 99, 234],
                    'decoded' => '<ï½œbeginâ–ofâ–sentenceï½œ>ê™ŠðŸ¦™',
                ],
                // 'Paragraph' => [
                //     'text' => TestStrings::LLAMA_PARAGRAPH,
                //     'tokens' => ['<ï½œbeginâ–ofâ–sentenceï½œ>', 'The', 'Ä ll', 'ama', 'Ä (/', 'Ã‹Äª', 'l', 'Ã‰', 'Äµ', 'Ã‹', 'Ä²', 'm', 'Ã‰Ä»', '/', ';', 'Ä Ã°Å', 'Â¦', 'Ä»', 'Spanish', 'Ä pronunciation', ':', 'Ä [', 'Ã‹Äª', 'ÃŠ', 'Ä°', 'ama', '])', 'Ä (', 'L', 'ama', 'Ä gl', 'ama', ')', 'Ä is', 'Ä a', 'Ä domestic', 'ated', 'Ä South', 'Ä American', 'Ä cam', 'el', 'id', ',', 'Ä widely', 'Ä used', 'Ä as', 'Ä a', 'Ä meat', 'Ä and', 'Ä pack', 'Ä animal', 'Ä by', 'Ä And', 'ean', 'Ä cultures', 'Ä since', 'Ä the', 'Ä Pre', '-', 'Col', 'umb', 'ian', 'Ä era', '.', 'Ä L', 'lam', 'as', 'Ä are', 'Ä social', 'Ä animals', 'Ä and', 'Ä live', 'Ä with', 'Ä others', 'Ä as', 'Ä a', 'Ä her', 'd', '.', 'Ä Their', 'Ä wool', 'Ä is', 'Ä soft', 'Ä and', 'Ä contains', 'Ä only', 'Ä a', 'Ä small', 'Ä amount', 'Ä of', 'Ä lan', 'ol', 'in', '.[', '2', ']', 'Ä L', 'lam', 'as', 'Ä can', 'Ä learn', 'Ä simple', 'Ä tasks', 'Ä after', 'Ä a', 'Ä few', 'Ä repet', 'itions', '.', 'Ä When', 'Ä using', 'Ä a', 'Ä pack', ',', 'Ä they', 'Ä can', 'Ä carry', 'Ä about', 'Ä ', '2', '5', 'Ä to', 'Ä ', '3', '0', '%', 'Ä of', 'Ä their', 'Ä body', 'Ä weight', 'Ä for', 'Ä ', '8', 'Ä to', 'Ä ', '1', '3', 'Ä km', 'Ä (', '5', 'Ã¢Ä¢Âµ', '8', 'Ä miles', ').', '[', '3', ']', 'Ä The', 'Ä name', 'Ä ll', 'ama', 'Ä (', 'in', 'Ä the', 'Ä past', 'Ä also', 'Ä sp', 'elled', 'Ä "', 'l', 'ama', '"', 'Ä or', 'Ä "', 'gl', 'ama', '")', 'Ä was', 'Ä adopted', 'Ä by', 'Ä European', 'Ä sett', 'lers', 'Ä from', 'Ä native', 'Ä Per', 'uv', 'ians', '.[', '4', ']', 'Ä The', 'Ä ancest', 'ors', 'Ä of', 'Ä llam', 'as', 'Ä are', 'Ä thought', 'Ä to', 'Ä have', 'Ä origin', 'ated', 'Ä from', 'Ä the', 'Ä Great', 'Ä Pl', 'ains', 'Ä of', 'Ä North', 'Ä America', 'Ä about', 'Ä ', '4', '0', 'Ä million', 'Ä years', 'Ä ago', ',', 'Ä and', 'Ä subsequently', 'Ä mig', 'rated', 'Ä to', 'Ä South', 'Ä America', 'Ä about', 'Ä three', 'Ä million', 'Ä years', 'Ä ago', 'Ä during', 'Ä the', 'Ä Great', 'Ä American', 'Ä Inter', 'change', '.', 'Ä By', 'Ä the', 'Ä end', 'Ä of', 'Ä the', 'Ä last', 'Ä ice', 'Ä age', 'Ä (', '1', '0', ',', '0', '0', '0', 'Ã¢Ä¢Âµ', '1', '2', ',', '0', '0', '0', 'Ä years', 'Ä ago', '),', 'Ä camel', 'ids', 'Ä were', 'Ä ext', 'inct', 'Ä in', 'Ä North', 'Ä America', '.[', '3', ']', 'Ä As', 'Ä of', 'Ä ', '2', '0', '0', '7', ',', 'Ä there', 'Ä were', 'Ä over', 'Ä seven', 'Ä million', 'Ä llam', 'as', 'Ä and', 'Ä al', 'pac', 'as', 'Ä in', 'Ä South', 'Ä America', 'Ä and', 'Ä over', 'Ä ', '1', '5', '8', ',', '0', '0', '0', 'Ä llam', 'as', 'Ä and', 'Ä ', '1', '0', '0', ',', '0', '0', '0', 'ÃªÄ»Ä¬', 'Ã°ÅÂ¦Ä»', 'Ä al', 'pac', 'as', ',', 'Ä desc', 'ended', 'Ä from', 'Ä pro', 'gen', 'itors', 'Ä imported', 'Ä late', 'Ä in', 'Ä the', 'Ä ', '2', '0', 'th', 'Ä century', ',', 'Ä in', 'Ä the', 'Ä United', 'Ä States', 'Ä and', 'Ä Canada', '.[', '5', ']', 'Ä In', 'Ä A', 'ym', 'ara', 'Ä myth', 'ology', ',', 'Ä llam', 'as', 'Ä are', 'Ä important', 'Ä beings', '.', 'Ä The', 'Ä Heaven', 'ly', 'Ä Ll', 'ama', 'Ä is', 'Ä said', 'Ä to', 'Ä drink', 'Ä water', 'Ä from', 'Ä the', 'Ä ocean', 'Ä and', 'Ä ur', 'in', 'ates', 'Ä as', 'Ä it', 'Ä ra', 'ins', '.[', '6', ']', 'Ä According', 'Ä to', 'Ä A', 'ym', 'ara', 'Ä es', 'chat', 'ology', ',', 'Ä llam', 'as', 'Ä will', 'Ä return', 'Ä to', 'Ä the', 'Ä water', 'Ä springs', 'Ä and', 'Ä l', 'ago', 'ons', 'Ä where', 'Ä they', 'Ä come', 'Ä from', 'Ä at', 'Ä the', 'Ä end', 'Ä of', 'Ä time', '.[', '6', ']'],
                //     'ids' => [32013, 546, 1703, 4204, 31905, 31459, 75, 131, 226, 133, 225, 76, 28747, 14, 26, 12394, 99, 234, 20786, 840, 9119, 25307, 25, 821, 31459, 132, 223, 4204, 5589, 334, 43, 4204, 1649, 4204, 8, 317, 245, 13569, 612, 5168, 4115, 4370, 282, 304, 11, 13620, 1219, 372, 245, 12342, 285, 2379, 9542, 457, 1306, 24391, 24783, 1952, 254, 7606, 12, 2608, 4313, 987, 2895, 13, 412, 8265, 281, 417, 3601, 8469, 285, 3516, 365, 3060, 372, 245, 706, 67, 13, 9195, 24547, 317, 2829, 285, 5396, 885, 245, 1752, 3733, 280, 27264, 313, 246, 9469, 17, 60, 412, 8265, 281, 482, 3059, 2966, 9227, 1164, 245, 1853, 15747, 2160, 13, 2463, 1242, 245, 2379, 11, 653, 482, 5642, 782, 207, 17, 20, 276, 207, 18, 15, 4, 280, 699, 3110, 4285, 327, 207, 23, 276, 207, 16, 18, 9004, 334, 20, 887, 23, 6595, 628, 58, 18, 60, 428, 1208, 1703, 4204, 334, 246, 254, 2872, 835, 731, 6679, 440, 75, 4204, 1, 409, 440, 2521, 4204, 2456, 438, 13509, 457, 8717, 6762, 12104, 473, 8118, 3043, 12466, 3091, 9469, 19, 60, 428, 18901, 710, 280, 15410, 281, 417, 2207, 276, 463, 6948, 612, 473, 254, 6984, 2284, 2200, 280, 5216, 6092, 782, 207, 19, 15, 4866, 1547, 4074, 11, 285, 23909, 8290, 9831, 276, 5168, 6092, 782, 1846, 4866, 1547, 4074, 2310, 254, 6984, 4115, 6660, 4865, 13, 3550, 254, 1223, 280, 254, 1554, 9405, 4489, 334, 16, 15, 11, 15, 15, 15, 887, 16, 17, 11, 15, 15, 15, 1547, 4074, 650, 4370, 282, 2929, 773, 1309, 5729, 279, 5216, 6092, 9469, 18, 60, 1725, 280, 207, 17, 15, 15, 22, 11, 741, 773, 851, 7970, 4866, 15410, 281, 285, 360, 79, 305, 281, 279, 5168, 6092, 285, 851, 207, 16, 20, 23, 11, 15, 15, 15, 15410, 281, 285, 207, 16, 15, 15, 11, 15, 15, 15, 164, 234, 219, 10047, 99, 234, 360, 79, 305, 281, 11, 1774, 2611, 473, 381, 4920, 6041, 26357, 5179, 279, 254, 207, 17, 15, 392, 8299, 11, 279, 254, 4783, 5098, 285, 8905, 9469, 20, 60, 680, 338, 1254, 3367, 25157, 2333, 11, 15410, 281, 417, 2364, 22792, 13, 428, 18933, 326, 9140, 4204, 317, 989, 276, 7371, 2345, 473, 254, 15439, 285, 8580, 246, 980, 372, 359, 1809, 1231, 9469, 21, 60, 10068, 276, 338, 1254, 3367, 707, 24570, 2333, 11, 15410, 281, 540, 967, 276, 254, 2345, 30851, 285, 284, 5980, 875, 1064, 653, 1857, 473, 429, 254, 1223, 280, 761, 9469, 21, 60],
                //     'decoded' => "<ï½œbeginâ–ofâ–sentenceï½œ>" . TestStrings::LLAMA_PARAGRAPH,
                // ],
            ],
        ];
    }
}
